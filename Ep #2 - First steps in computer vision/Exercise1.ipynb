{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the course you learned how to do classification using Fashion MNIST, a data set containing items of clothing. There's another, similar dataset called MNIST which has items of handwriting -- the digits 0 through 9.\n",
    "\n",
    "Write an MNIST classifier that trains to 99% accuracy or above, and does it without a fixed number of epochs -- i.e. you should stop training once you reach that level of accuracy.\n",
    "\n",
    "Some notes:\n",
    "\n",
    "It should succeed in less than 10 epochs, so it is okay to change epochs to 10, but nothing larger\n",
    "When it reaches 99% or greater it should print out the string \"Reached 99% accuracy so cancelling training!\"\n",
    "If you add any additional variables, make sure you use the same names as the ones used in the class\n",
    "I've started the code for you below -- how would you finish it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "IMAGE_SIZE = 28\n",
    "# Keras's default learning rate is 1e-3\n",
    "LEARNING_RATE = 1e-3\n",
    "# Keras's default batch size is 32\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Providing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor()\n",
    "train_dataset = datasets.MNIST('../data/MNIST', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST('../data/MNIST', train=False, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define and Compile the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CrossEntropyLoss in PyTorch assumes unnormalized values, thus Softmax should not be used\n",
    "# https://stackoverflow.com/a/61438119\n",
    "model = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(IMAGE_SIZE * IMAGE_SIZE, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, 10),\n",
    "#     nn.Softmax(dim=-1)\n",
    ")\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "loss: 2.315169e-01 - acc: 0.9324166666666667\n",
      "Epoch 2/10\n",
      "loss: 9.158986e-02 - acc: 0.97235\n",
      "Epoch 3/10\n",
      "loss: 5.555138e-02 - acc: 0.9837333333333333\n",
      "Epoch 4/10\n",
      "loss: 3.477582e-02 - acc: 0.9896333333333334\n",
      "Epoch 5/10\n",
      "loss: 2.373431e-02 - acc: 0.9923166666666666\n",
      "Reached 99% accuracy so cancelling training!\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    print(f'Epoch {epoch+1}/{EPOCHS}')\n",
    "    loss_sum = 0\n",
    "    correct = 0\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(images)\n",
    "        loss = loss_fn(out, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        _, predicted = torch.max(out.data, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        loss_sum += loss.item()\n",
    "\n",
    "    acc = correct / len(train_dataset)\n",
    "    print(f'loss: {loss_sum / len(train_loader):e} - acc: {acc}')\n",
    "    \n",
    "    if acc > 0.99:\n",
    "        print('Reached 99% accuracy so cancelling training!')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 97.74%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        out = model(images)\n",
    "        _, predicted = torch.max(out.data, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(f'Test accuracy: {100 * correct / len(test_dataset)}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
